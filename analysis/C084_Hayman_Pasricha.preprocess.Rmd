---
title: "Preprocessing the Hayman/Pasricha (C084) ZIPT mini-bulk data set"
description: |
author:
  - name: Peter Hickey
    url: https://peterhickey.org
    affiliation: WEHI SCORE
    affiliation_url: https://www.wehi.edu.au/people/shalin-naik/3310/score
date: "`r Sys.Date()`"
output: distill::distill_article
editor_options:
  chunk_output_type: console
bibliography: ref.bib
---

```{r setup}
library(SingleCellExperiment)
library(here)
library(rmarkdown)
library(janitor)
library(ggplot2)
library(patchwork)
library(BiocParallel)
library(scater)
library(cowplot)
library(limma)
library(scales)

# NOTE: Using >= 4 cores seizes up my laptop. Can use more on RStudio server.
options(
  "mc.cores" = 
    ifelse(Sys.info()[["nodename"]] == "rstudio-1.hpc.wehi.edu.au", 8L, 2L))

register(MulticoreParam(workers = getOption("mc.cores")))

knitr::opts_chunk$set(fig.path = "C084_Hayman_Pasricha.preprocess_files/")
```

# Setting up the data

We start from the count matrices created in [`code/scPipe.R`](../code/scPipe.R`), specifically the [UMI counts (a.k.a. UMI-deduplicated) data](../data/SCEs/C084_Hayman_Pasricha.UMI_deduped.scPipe.SCE.rds) and [read counts (a.k.a. not UMI-deduplicated) data](../data/SCEs/C084_Hayman_Pasricha.not_UMI_deduped.scPipe.SCE.rds).

<aside>
UMI stands for unique molecular identifier.
</aside>

```{r}
sce_deduped <- readRDS(
  here("data", "SCEs", "C084_Hayman_Pasricha.UMI_deduped.scPipe.SCE.rds"))
sce_not_deduped <- readRDS(
  here("data", "SCEs", "C084_Hayman_Pasricha.not_UMI_deduped.scPipe.SCE.rds"))

colnames(sce_not_deduped) <- sub(
  "\\.not_UMI_deduped",
  "",
  colnames(sce_not_deduped))
stopifnot(
  identical(rownames(sce_deduped), rownames(sce_not_deduped)),
  identical(colnames(sce_deduped), colnames(sce_not_deduped))) 
sce <- sce_deduped
assay(sce, "UMI_counts") <- assay(sce_deduped, "counts")
assay(sce, "read_counts") <- assay(sce_not_deduped, "counts")
```

We combine these into a single object^[In the terminology of Bioconductor this is called a *SingleCellExperiment* object.] containing both the UMI counts and the read counts for `r nrow(sce)` genes and `r ncol(sce)` samples.

## Incorporating gene-based annotation

We obtain gene-based annotations from the NCBI/RefSeq and Ensembl databases, such as the chromosome and gene symbol, using the `r BiocStyle::Biocpkg("Homo.sapiens")` and `r BiocStyle::Biocpkg("EnsDb.Hsapiens.v86")` packages.

```{r}
# Extract rownames (Ensembl IDs) to use as key in database lookups.
ensembl <- rownames(sce)

# Pull out useful gene-based annotations from the Ensembl-based database.
library(EnsDb.Hsapiens.v86)
library(ensembldb)
# NOTE: These columns were customised for this project.
ensdb_columns <- c(
  "GENEBIOTYPE", "GENENAME", "GENESEQSTART", "GENESEQEND", "SEQNAME", "SYMBOL")
names(ensdb_columns) <- paste0("ENSEMBL.", ensdb_columns)
stopifnot(all(ensdb_columns %in% columns(EnsDb.Hsapiens.v86)))
ensdb_df <- DataFrame(
  lapply(ensdb_columns, function(column) {
    mapIds(
      x = EnsDb.Hsapiens.v86, 
      # NOTE: Need to remove gene version number prior to lookup.
      keys = gsub("\\.[0-9]+$", "", ensembl),
      keytype = "GENEID",
      column = column,
      multiVals = "CharacterList")
  }),
  row.names = ensembl)
# NOTE: Can't look up GENEID column with GENEID key, so have to add manually.
ensdb_df$ENSEMBL.GENEID <- ensembl

# NOTE: Homo.sapiens combines org.Hs.eg.db and
#       TxDb.Hsapiens.UCSC.hg38.knownGene (as well as others) and therefore 
#       uses entrez gene and RefSeq based data.
library(Homo.sapiens)
# NOTE: These columns were customised for this project.
ncbi_columns <- c(
  # From TxDB: None required
  # From OrgDB
  "ALIAS", "ENTREZID", "GENENAME", "REFSEQ", "SYMBOL")
names(ncbi_columns) <- paste0("NCBI.", ncbi_columns)
stopifnot(all(ncbi_columns %in% columns(Homo.sapiens)))
ncbi_df <- DataFrame(
  lapply(ncbi_columns, function(column) {
    mapIds(
      x = Homo.sapiens, 
      # NOTE: Need to remove gene version number prior to lookup.
      keys = gsub("\\.[0-9]+$", "", ensembl),
      keytype = "ENSEMBL",
      column = column,
      multiVals = "CharacterList")
  }),
  row.names = ensembl)

rowData(sce) <- cbind(ensdb_df, ncbi_df)
```

Having quantified gene expression against the GENCODE gene annotation, we have Ensembl-style identifiers for the genes. 
These identifiers are used as they are unambiguous and highly stable. 
However, they are difficult to interpret compared to the gene symbols which are more commonly used in the literature.
Henceforth, we will use gene symbols (where available) to refer to genes in our analysis and otherwise use the Ensembl-style gene identifiers^[Some care is taken to account for missing and duplicate gene symbols; missing symbols are replaced with the Ensembl identifier and duplicated symbols are concatenated with the (unique) Ensembl identifiers.].

```{r}
# Replace the row names of the SCE by the gene symbols (where available).
rownames(sce) <- uniquifyFeatureNames(
  ID = rownames(sce), 
  # NOTE: An Ensembl ID may map to 0, 1, 2, 3, ... gene symbols.
  #       When there are multiple matches only the 1st match is used.
  names = sapply(rowData(sce)$ENSEMBL.SYMBOL, function(x) {
    if (length(x)) {
      x[[1]]
    } else {
      NA_character_
    }
    }))
```

```{r}
# Some useful gene sets
mito_set <- rownames(sce)[any(rowData(sce)$ENSEMBL.SEQNAME == "MT")]

ribo_set <- grep("^RP(S|L)", rownames(sce), value = TRUE)
# NOTE: A more curated approach for identifying ribosomal protein genes 
#       (https://github.com/Bioconductor/OrchestratingSingleCellAnalysis-base/blob/ae201bf26e3e4fa82d9165d8abf4f4dc4b8e5a68/feature-selection.Rmd#L376-L380)
library(msigdbr)
c2_sets <- msigdbr(species = "Homo sapiens", category = "C2")
ribo_set <- union(
  ribo_set,
  c2_sets[c2_sets$gs_name == "KEGG_RIBOSOME", ]$gene_symbol)

e <- new.env()
load(url("http://bioinf.wehi.edu.au/software/GenderGenes/GenderGenes.RData"), e)
sex_set <- rownames(sce)[
  any(rowData(sce)$NCBI.ENTREZID %in% c(e$XiEgenes, e$msYgenes))]

pseudogene_set <- rownames(sce)[
  any(grepl("pseudogene", rowData(sce)$ENSEMBL.GENEBIOTYPE))]

hemo_set <- rownames(sce)[
  any(grepl("hemoglobin subunit", rowData(sce)$NCBI.GENENAME))]
```

## Incorporating sample-based annotation

Cell-based annotations are included in the *colData* of the *SingleCellExperiment*.
In particular, we include all the sample metadata provided by Tom in the [`data/sample_sheets/ZIPT metadata.xlsx`](../data/sample_sheets/ZIPT metadata.xlsx) spreadsheet by matching samples on the `ID` column.

```{r}
sample_metadata <- readxl::read_excel(
  here("data/sample_sheets/ZIPT metadata.xlsx"))

keep_coldata_columns <-  c(
  "plate_number", "well_position", "c_rt1_primer_name",
  "rd1_index_cell_index_index_sequence_as_in_c_rt1_primer",
  "illumina_index_index_number_separate_index_read",
  "illumina_index_index_sequence_separate_index_read",
  "rt1_index_primer_sequences",
  "well_position_in_original_dilution_layout", "sequencing_run", "id", "group",
  "collection_date", "sample_serum", "rna", "cytof_1", "cytof_2",
  "location_box", "position", "timepoint")
new_colData <- as(
  dplyr::inner_join(
    as.data.frame(colData(sce)[, keep_coldata_columns]),
    sample_metadata,
    by = c("id" = "ID")),
  "DataFrame")

# Drop redundant columns.
stopifnot(identical(new_colData[["group"]], new_colData[["Group"]]))
new_colData[["Group"]] <- NULL

# Manually tweak some column types.
new_colData[["plate_number"]] <- factor(new_colData[["plate_number"]])
new_colData[["sequencing_run"]] <- factor(new_colData[["sequencing_run"]])
new_colData[["id"]] <- factor(new_colData[["id"]])
new_colData[["group"]] <- factor(new_colData[["group"]])
new_colData[["sex"]] <- factor(new_colData[["sex"]])
new_colData[["AnyDiarrhea2wk0"]] <- as.logical(new_colData[["AnyDiarrhea2wk0"]])
new_colData[["AnyDiarrhea2wk24"]] <- as.logical(
  new_colData[["AnyDiarrhea2wk24"]])
new_colData[["Wasted0"]] <- as.logical(new_colData[["Wasted0"]])
new_colData[["Wasted12"]] <- as.logical(new_colData[["Wasted12"]])
new_colData[["Wasted24"]] <- as.logical(new_colData[["Wasted24"]])
new_colData[["Stunted0"]] <- as.logical(new_colData[["Stunted0"]])
new_colData[["Stunted12"]] <- as.logical(new_colData[["Stunted12"]])
new_colData[["Stunted24"]] <- as.logical(new_colData[["Stunted24"]])

colData(sce) <- new_colData
```

The complete sample metadata is shown below.

```{r}
paged_table(sample_metadata)
```

The table below summarises the number of samples in each experimental group at each timepoint (samples are paired between timepoints).

```{r}
as.data.frame(colData(sce)) %>%
  # NOTE: The plates technical triplicates, so it suffices to look at a single 
  #       plate.
  dplyr::filter(plate_number == "LCE475") %>%
  janitor::tabyl(group, timepoint) %>%
  knitr::kable(caption = "Number of samples per group/timepoint.")
```

# Failure of `LCE475`

There are 3 batches of samples in total - `r glue::glue_collapse(unique(sce$plate_number), sep = ", ", last = ", and ")` - and these are technical replicates of one another (i.e. each well contains the same sample across all 3 batches).

It was not the original plan to have each sample in triplicate across batches.
The `LCE475` batch was intended to be the only batch, but something went wrong in the library preparation and it generated very few reads (maximum library size in reads = `r max(colSums(assay(sce, "read_counts")[, sce$plate_number == "LCE475"]))`).
According to Daniel Brown, likely what happened is that there was carry-over of a large number of molecules without adapters, which meant that the `LCE475` library contained few sequence-able molecules.
We therefore remove the `LCE475` batch from further analysis.

```{r}
sce <- sce[, sce$plate_number != "LCE475"]
colData(sce) <- droplevels(colData(sce))
```

Following the failure of `LCE475`, the library preparation was repeated several times, documented in the table below^[Table provided by Tracey Baldwin ([2020-08-11 on MS Teams](https://teams.microsoft.com/l/message/19:37f4d7eed15843cfade0a7855f6acb37@thread.skype/1597130506674?tenantId=aa7c72e2-c5cf-4a40-a22a-a585c04ca07c&groupId=864577ca-cf80-43f9-978d-10f80251cbde&parentMessageId=1596777680068&teamName=SCORE&channelName=General&createdTime=1597130506674))].

```{r}
plate_descriptions_df <- read.csv(
    here("data/sample_sheets/plate_descriptions.csv"),
    check.names = FALSE) %>%
    janitor::clean_names()
knitr::kable(
  plate_descriptions_df,
  caption = "Descriptions of additional library preparations.")
```

Ultimately, the 'LC475 mini bulk back up 1:10 dilution' (`C084_LC475_mini_bulk_back_up_1:10`; henceforth abbreviate to `LC475`) and 'LC476 mini bulk original (1ng/uL)' (`LCE_476_BU_8_cycle`; henceforth abbreviate to `LC476`) library preparations were taken forward and sequenced in run `NN183`.

```{r}
# Rename plates and samples.
sce$plate_number <- factor(
  ifelse(sce$plate_number == "LCE_476_BU_8_cycle", "LC476", "LC475"))
colnames(sce) <- paste0(paste0(sce$plate_number, "_", sce$well_position))

# Some useful colours
plate_number_colours <- setNames(
  palette.colors(9)[1:2],
  levels(sce$plate_number))[seq_len(nlevels(sce$plate_number))]
sce$plate_number_colours <- plate_number_colours[sce$plate_number]
group_colours <- setNames(
  palette.colors(9)[3:5],  
  levels(sce$group))
sce$group_colours <- group_colours[sce$group]
timepoint_colours <- setNames(
  palette.colors(9)[6:7],  
  levels(sce$timepoint))
sce$timepoint_colours <- timepoint_colours[timepoint_colours]
sex_colours <- setNames(
  RColorBrewer::brewer.pal(4, "Set1")[1:2],
  levels(sce$sex))
sce$sex_colours <- sex_colours[sce$sex]
```

# Have we sequenced enough?

## Motivation

SCORE's mini-bulk protocol is still being finalised and some technical questions remain.
In particular, we want to know if we have sequenced enough to answer the biological questions of interest.

One way of estimating if we have sequenced enough uses a metric called 'sequencing saturation'.
10x Genomics have some useful information about sequencing saturation available [here](https://kb.10xgenomics.com/hc/en-us/articles/115005062366-What-is-sequencing-saturation-).
In particular,

>  Sequencing saturation is a measure of the fraction of library complexity that was sequenced in a given experiment. The inverse of the sequencing saturation can be interpreted as the number of additional reads it would take to detect a new transcript. ... Sequencing saturation is dependent on the library complexity and sequencing depth. Different cell types will have different amounts of RNA and thus will differ in the total number of different transcripts in the final library (also known as library complexity). ... As sequencing depth increases, more genes are detected, but this reaches saturation at different sequencing depths depending on cell type. ... Sequencing depth also affects sequencing saturation; generally, the more sequencing reads, the more additional unique transcripts you can detect. However, this is limited by the library complexity.

This naturally leads to the question of ['how much sequencing saturation should I aim for?'](https://kb.10xgenomics.com/hc/en-us/articles/115002474263-How-much-sequencing-saturation-should-I-aim-for-), which very much depends on the goals of the experiment.
For this experiment, where we wish to assess differential expression between treatment arms, we will likely want quite high sequencing saturation.

## Analysis

To begin, we simply examine the number of reads sequenced/sample.

```{r}
reads_ls <- log10(colSums(assay(sce, "read_counts")))
```

Figure \@ref(fig:read-library-size) plots the distribution of the number of reads mapped to exons in each sample^[I.e. the 'library size' when using read counts].
We see that obtain more reads/sample on average for samples on the `LC476` plate (median = `r number(median(10 ^ reads_ls[sce$plate_number == "LC476"]), big.mark = ",")`) than for samples on the `LC475` (median = `r number(median(10 ^ reads_ls[sce$plate_number == "LC475"]), big.mark = ",")`).

```{r read-library-size, fig.asp = 1 / 2, fig.cap = "Distribution of the number of reads mapped to exons in each sample, stratified by plate."}
par(mfrow = c(1, 2))
plot(
  density(reads_ls[sce$plate_number == "LC475"]),
  xlab = expression(log[10](n[reads])),
  main = "LC475",
  ylab = "density",
  xlim = range(reads_ls))
plot(
  density(
    reads_ls[sce$plate_number == "LC476"]),
  xlab = expression(log[10](n[reads])),
  main = "LC476",
  ylab = "density",
  xlim = range(reads_ls))
```

```{r}
hemo_prop <- colSums(assay(sce, "read_counts")[hemo_set, ]) / 10 ^ reads_ls
```

Unfortunately, a large proportion of these reads come from hemoglobin subunit genes (`r glue::glue_collapse(sort(hemo_set), sep = ", ", last = ", and ")`).
Figure \@ref(fig:hemo-prop) shows that we obtain on average a greater proportion of reads from the hemoglobin subunit genes for samples on the `LC476` plate (median = `r percent(median(hemo_prop[sce$plate_number == "LC476"]))`) than for samples on the `LC475` plate (median = `r percent(median(hemo_prop[sce$plate_number == "LC475"]))`).

```{r hemo-prop, fig.asp = 1 / 2, fig.cap = "Distribution of the proportion of reads mapped to hemoglobin subunit genes, stratified by plate."}
par(mfrow = c(1, 2))
plot(
  density(
    hemo_prop[sce$plate_number == "LC475"],
    from = 0,
    to = 1),
  xlab = expression(prop[hemo]),
  main = "LC475",
  ylab = "density",
  xlim = c(0, 1))
plot(
  density(
    hemo_prop[sce$plate_number == "LC476"],
    from = 0,
    to = 1),
  xlab = expression(prop[hemo]),
  main = "LC476",
  ylab = "density",
  xlim = c(0, 1))
```

We estimate the sequencing saturation using [10x Genomics' formula](https://kb.10xgenomics.com/hc/en-us/articles/115003646912-How-is-sequencing-saturation-calculated-), 

$$
1 - (n_{deduped reads} / n_{reads})
$$
where $n_{deduped reads}$ = Number of unique (valid cell-barcode, valid UMI, gene)-combinations among confidently mapped reads and $n_{reads}$ = Total number of confidently mapped, valid cell-barcode, valid UMI reads.

```{r}
saturation <- 1 - 
  (colSums(assay(sce, "UMI_counts")) / colSums(assay(sce, "read_counts")))
saturation_hemo <- 1 - 
  (colSums(assay(sce, "UMI_counts")[hemo_set, ]) /
     colSums(assay(sce, "read_counts")[hemo_set, ]))
saturation_no_hemo <- 1 - 
  (colSums(assay(sce, "UMI_counts")[setdiff(rownames(sce), hemo_set), ]) /
     colSums(assay(sce, "read_counts")[setdiff(rownames(sce), hemo_set), ]))
```

Figure \@ref(fig:saturation) shows that the hemoglobin subunit genes are sequenced to near-total saturation, whereas the rest of the transcriptome reaches just over 50% sequencing saturation for most samples with a higher on average sequencing saturation of non-hemoglobin subunit genes for samples on the `LC476` plate (median = `r percent(median(saturation_no_hemo[sce$plate_number == "LC476"]))`) than for samples on the `LC475` plate (median  = `r percent(median(saturation_no_hemo[sce$plate_number == "LC475"]))`).

```{r saturation, fig.asp = 3 / 2, fig.cap = "Distribution of the sequencing saturation of different classes of genes, stratified by plate."}
par(mfrow = c(3, 2))
plot(
  density(
    saturation[sce$plate_number == "LC475"],
    from = 0,
    to = 1),
  xlab = "saturation",
  main = "LC475",
  ylab = "density",
  xlim = c(0, 1),
  sub = "All genes")
plot(
  density(
    saturation[sce$plate_number == "LC476"],
    from = 0,
    to = 1),
  xlab = "saturation",
  main = "LC476",
  ylab = "density",
  xlim = c(0, 1),
  sub = "All genes")
plot(
  density(
    saturation_no_hemo[sce$plate_number == "LC475"],
    from = 0,
    to = 1),
  xlab = "saturation",
  main = "LC475",
  ylab = "density",
  xlim = c(0, 1),
  sub = "No hemoglobin subunits")
plot(
  density(
    saturation_no_hemo[sce$plate_number == "LC476"],
    from = 0,
    to = 1),
  xlab = "saturation",
  main = "LC476",
  ylab = "density",
  xlim = c(0, 1),
  sub = "No hemoglobin subunits")
plot(
  density(
    saturation_hemo[sce$plate_number == "LC475"],
    from = 0,
    to = 1),
  xlab = "saturation",
  main = "LC475",
  ylab = "density",
  xlim = c(0, 1),
  sub = "Hemoglobin subunits")
plot(
  density(
    saturation_hemo[sce$plate_number == "LC476"],
    from = 0,
    to = 1),
  xlab = "saturation",
  main = "LC476",
  ylab = "density",
  xlim = c(0, 1),
  sub = "Hemoglobin subunits")
```

## Summary

These results show that the libraries are massively enriched for sequences from hemoglobin subunit genes and we have consequently over-sequenced these genes and likely under-sequenced the rest of the transcriptome.
Further sequencing of these samples may therefore be necessary.

<aside>
We would likely pick just one of `LC475` and `LC476` for further sequencing.
</aside>

One way to think of sequencing saturation is [provided by 10x Genomics](https://kb.10xgenomics.com/hc/en-us/articles/115002474263-How-much-sequencing-saturation-should-I-aim-for-):

> The inverse of the sequencing saturation can be interpreted as roughly the number of new transcripts you expect to find with one new read. If sequencing saturation is at 50%, it means that every 2 new reads will result in 1 new UMI count (unique transcript) detected. In contrast, 90% sequencing saturation means that 10 new reads are necessary to obtain one new UMI count. If the sequencing saturation is high, additional sequencing would not recover much new information for the library.

However, remember that in doing further sequencing we will still be 'paying the price' of further sequencing the hemoglobin subunit genes, i.e. the new transcripts we identify are likely to include a large proportion of additional hemoglobin subunit transcripts.

An alternative to simply re-sequencing the existing library may be to first perform a technique like 'DASH', which uses "recombinant Cas9 protein complexed with a library of guide RNAs targeting unwanted species for cleavage, thus preventing them from consuming sequencing space" [@gu2016depletion].
The feasibility/suitability of using such a technique for this project would require further discussion with SCORE.

# UMI counts vs. read counts

## Motivation

A unique feature of SCORE's 'mini-bulk' RNA-sequencing protocol is the incorporation of unique molecular identifiers (UMIs) into the library preparation; an ordinary bulk RNA-seq protocol does not incorporate UMIs.

UMIs are commonly used in single-cell RNA-sequencing protocols, such as the CEL-Seq2 protocol from which the mini-bulk protocol is adapted.
UMIs are molecular tags that are used to detect and quantify unique mRNA transcripts.
In this method, mRNA libraries are generated by fragmentation and reverse-transcribed to cDNA.
Oligo(dT) primers with specific sequencing linkers are added to the cDNA.
Another sequencing linker with a 6 bp random label and an index sequence is added to the 5' end of the template, which is amplified and sequenced.

<aside>
This explanation is adapted from [https://sapac.illumina.com/science/sequencing-method-explorer/kits-and-arrays/umi.html](https://sapac.illumina.com/science/sequencing-method-explorer/kits-and-arrays/umi.html).
</aside>

The UMI count is always less than or equal to the read count and a UMI count of zero also implies a read count of zero.

Pros of using UMIs:

- Can sequence unique mRNA transcripts
- Can detect transcripts occurring at low frequencies
- Transcripts can be quantified based on sequencing reads specific to each barcode

Cons of using UMIs:

- SCORE's mini-bulk protocol uses a $k=6$ bp UMI^[The choice of a 6 bp UMI in the mini-bulk protocol is because it is adapted from SCORE's CEL-Seq2 single-cell RNA-sequencing protocol. With scRNA-seq data it is very rare to observe more than $4^k = 4^6 = 4096$ unique molecules for any one gene.] and so (theoretically) the maximum UMI count for each gene is $4^6 = 4096$.
- There is therefore a risk that highly expressed genes may have their expression measurements artificially truncated, particularly if the sample is deeply sequenced.

To investigate whether expression measurements are being 'truncated' in this dataset, and decide whether to use the UMI counts or the read counts, we generated and now analyse two count matrices:

1. UMI counts (i.e. deduplicating UMI counts)
2. Read counts (i.e. not deduplicating UMI counts, equivalent to ignoring the UMIs)

## Analysis

Figure \@ref(fig:read-distribution) plots the distribution of the logarithm of the read counts.
From this we see that the vast majority of read counts are small. 
In fact:

- `r percent(sum(as.vector(assay(sce, "read_counts")) == 0) / prod(dim(sce)), accuracy = 0.1)` of read counts are 0
- 95% of the read counts are no greater than `r quantile(as.vector(assay(sce, "read_counts")), 0.95)` 
- 99% of the read counts are no greater than `r quantile(as.vector(assay(sce, "read_counts")), 0.99)` 
- 99.9% of the read counts are no greater than `r quantile(as.vector(assay(sce, "read_counts")), 0.999)`

Most importantly, only (`r percent(sum(as.vector(assay(sce, "read_counts")) > 4^6) / prod(dim(sce)), accuracy = 0.001)`) of read counts exceed the $4^6 = 4096$ threshold.

<aside>
Surprisingly, `r percent(sum(as.vector(assay(sce, "UMI_counts")) > 4^6) / prod(dim(sce)), accuracy = 0.001)` of UMI counts exceed the theoretical maximum of $4^6=4096$. At this stage it is not clear to me how this can occur.
</aside>

```{r read-distribution, fig.cap = "Distribution of the logarithm of the read counts as density plot (left) and empirical cumulative distribution function (right). A count of 1 is added to each UMI count to avoid taking the logarithm of zero. The orange vertical line denotes $4^6 = 4096$.", fig.asp = 1 / 2}
x <- as.vector(assay(sce, "read_counts")) + 1

par(mfrow = c(1, 2), cex = 0.5)
plot(
  density(log2(x), from = min(log2(x)), to = max(log2(x))),
  xlab = expression(log[2](reads + 1)),
  main = "",
  ylab = "density")
abline(v = log2(4 ^ 6), col = "orange")
plot(
  ecdf(log2(x)), 
  xlim = range(log2(x)),
  main = "",
  xlab = expression(log[2](reads + 1)),
  ylab = "cumulative density")
abline(v = log2(4 ^ 6), col = "orange")
```

The only genes with read counts exceeding the $4^6=4096$ threshold are shown in the table below.
If we were to use the UMI counts, the genes in this list may have their expression measurements artificially truncated in those samples where the number of copies of the transcript exceed the $4^6=4096$ threshold.
There are a few points worth drawing attention to based on this table:

1. The 3 worst offenders are all hemoglobin subunits
2. There are several mitochondrial and ribosomal protein genes on the list
3. There are some key immune genes on the list, e.g., *PTPRC* (encoding CD45), *B2M*, and *HLA-B*

```{r}
n <- apply(assay(sce, "read_counts"), 1, function(x) sum(x > 4 ^ 6))
g <- names(n[n > 0])
read_e <- as.matrix(assay(sce, "read_counts")[g, ])
umi_e <- as.matrix(assay(sce, "UMI_counts")[g, ])
high_count_tbl <- tibble::tibble(
  gene = g,
  read_median_count = matrixStats::rowMedians(read_e),
  read_exceed_sum = matrixStats::rowSums2(read_e > 4 ^ 6),
  read_exceed_percent = read_exceed_sum / ncol(sce),
  umi_median_count = matrixStats::rowMedians(umi_e),
  umi_exceed_sum = matrixStats::rowSums2(umi_e > 4 ^ 6),
  umi_exceed_percent = umi_exceed_sum / ncol(sce)) %>%
  dplyr::arrange(desc(read_exceed_sum))

sketch <- htmltools::withTags(table(
  class = "display",
  thead(
    tr(
      th(rowspan = 2, "gene"),
      th(colspan = 3, "reads"),
      th(colspan = 3, "UMIs")
    ),
    tr(
      lapply(rep(c("median count", "N > 4096", "% > 4096"), 2), th)
    )
  )
))

DT::datatable(
  high_count_tbl, 
  caption = "Genes for which any sample has a read count exceeding the 4096 threshold and summaries of the corresponding read and UMI counts, namely: the median count ('median count'); the number of samples for which the counts exceed the threshold ('N > 4096'); and the percentage of samples for which the counts exceed the threshold ('% > 4096').",
  container = sketch,
  rownames = FALSE) %>%
  DT::formatPercentage(
    columns = c("read_exceed_percent", "umi_exceed_percent"),
    digits = 1) %>%
  DT::formatRound(
    columns = c("read_median_count", "umi_median_count"),
    digits = 0)
```

We can investigate this list more formally using a statistical test for over-representation of gene ontology (GO) terms in this gene set.
This is done using the `goana()` function from the `r BiocStyle::Biocpkg("limma")` package.
These results are shown in the table below. 
Several of the top GO terms relate to haptoglobin and hemoglobin, mitochondrial functions, and immune terms.
However, it is somewhat concerning to see 'response to stress' at the top of this list, which may indicate the sample quality was compromised prior to or during library preparation.

```{r}
# NOTE: kegga() was uninformative.
go <- goana(unlist(rowData(sce[g, ])$NCBI.ENTREZID), species = "Hs")
tg <- topGO(go, number = Inf)
DT::datatable(
  tg[tg$P.DE < 0.05, ],
  caption = "Most significant GO terms for genes with read counts that exceed the 4096 threshold. Report columns are the ontology that the GO term belongs to ('Ont'); the number of genes in the GO term ('N'); the number of genes in the DE set ('DE'); and the p-value for over-representation of the GO term in the set ('P.DE'). The p-values returned are unadjusted for multiple testing because GO terms are often overlapping, so standard methods of p-value adjustment may be very conservative. This means that only very small p-values should be used for published results.") %>%
  DT::formatRound(columns = "P.DE", digits = 9)
```

Figure \@ref(fig:scatterplot-and-ma-plot) plots the relationship between UMI counts and read counts for all genes and samples.
There are a few notable points about this figure:

1. The UMI counts and read counts are very strongly associated.
2. The log-fold change between the read counts and the UMI counts can be large, indicating the UMI counts are likely removing substantial PCR amplification noise.
3. The log-fold changes between the read counts and the UMI counts are larger on average for more highly expressed genes. The variation in the log-fold change is larger for the lowly expressed genes.
4. The hemoglobin genes stand out. These genes are extremely highly expressed, meaning that they likely saturate the 6 bp UMIs and which leads to the strange relationship between the UMI counts and the read counts for these genes.

```{r scatterplot-and-ma-plot, fig.cap = "Scatterplot of the logarithm of the UMI and read counts (top) and logCPM of the UMI and read counts (bottom) for all genes and samples (left) and mean-difference plot of the same data (right). The correlation in the scatterplot is reported below the x-axis label. Genes that are hemoglobin subunits are highlighted in red. The orange lines denote $4^6 = 4096$ and the blue line is a trend fitted to the mean-differences.", fig.asp = 1}
x <- log2(as.vector(assay(sce, "UMI_counts")) + 1)
y <- log2(as.vector(assay(sce, "read_counts")) + 1)
m <- (x + y) / 2
d <- y - x
g <- rep(rownames(sce), ncol(sce))
# NOTE: Only showing unique points for plotting speed.
i <- !duplicated(paste0(x, ".", y))

X <- edgeR::cpm(assay(sce, "UMI_counts"), log = TRUE)
Y <- edgeR::cpm(assay(sce, "read_counts"), log = TRUE)
M <- (X + Y) / 2
D <- y - x
G <- g
# NOTE: Only showing unique points for plotting speed.
I <- !duplicated(paste0(x, ".", y))

par(mfrow = c(2, 2))
plotWithHighlights(
  x = x[i],
  y = y[i],
  status = g[i] %in% hemo_set, 
  legend = FALSE,
  bg.pch = ".",
  hl.pch = ".",
  hl.col = "red",
  hl.cex = 3,
  sub = paste0("r = ", number(cor(x, y), accuracy = 0.001)),
  xlab = expression(log[2](UMIs + 1)),
  ylab = expression(log[2](reads + 1)))
abline(a = 0, b = 1, lty = 2, col = "grey")

plotWithHighlights(
  x = m[i] / 2,
  y = d[i],
  pch = ".",
  status = g[i] %in% hemo_set, 
  legend = FALSE,
  bg.pch = ".",
  hl.pch = ".",
  hl.col = "red",
  hl.cex = 3,
  xlab = "Average log-(count+1)",
  ylab = "logFC (reads vs. UMIs)",
  ylim = c(-max(abs(c(d, D))), max(abs(c(d, D)))))
abline(h = 0, lty = 2, col = "grey")
l <- lowess(m, d, f = 0.1)
lines(l, col = "dodgerBlue", lwd = 2)

plotWithHighlights(
  x = X[I],
  y = Y[I],
  status = G[I] %in% hemo_set, 
  legend = FALSE,
  bg.pch = ".",
  hl.pch = ".",
  hl.col = "red",
  hl.cex = 3,
  sub = paste0(
    "r = ", 
    number(cor(as.vector(X), as.vector(Y)), accuracy = 0.001)),
  xlab = expression(logCPM(UMIs)),
  ylab = expression(logCPM(reads)))
abline(a = 0, b = 1, lty = 2, col = "grey")

plotWithHighlights(
  x = M[I],
  y = D[i],
  status = G[I] %in% hemo_set, 
  legend = FALSE,
  bg.pch = ".",
  hl.pch = ".",
  hl.col = "red",
  hl.cex = 3,
  xlab = "Average logCPM",
  ylab = "logFC (reads vs. UMIs)",
  ylim = c(-max(abs(c(d, D))), max(abs(c(d, D)))))
abline(h = 0, lty = 2, col = "grey")
l <- lowess(M, D, f = 0.1)
lines(l, col = "dodgerBlue", lwd = 2)
```

Rather than looking at all samples and all genes at once, can also examine the relationship between UMI counts and read counts within a single sample across genes (Figure \@ref(fig:within-sample-cors)) and within a single gene across samples (Figure \@ref(fig:within-gene-cors)).

```{r}
x <- log2(as.matrix(assay(sce, "UMI_counts")) + 1)
y <- log2(as.matrix(assay(sce, "read_counts")) + 1)

cor_j <- diag(cor(x, y))
# NOTE: Splitting up the cor() computations is a hack to improve speed whilst 
#       keeping memory usage somewhat under control.
b <- 1000
s <- seq(1, by = b, to = nrow(sce))
e <- pmin(s + b - 1, nrow(sce))
cor_i <- unlist(
  Map(
    f = function(ss, ee ) diag(cor(t(x[ss:ee, ]), t(y[ss:ee, ]))),
    ss = s,
    ee = e))
```

These figures show that the UMI counts and read counts are highly correlated across both samples (median = `r number(median(cor_j, na.rm = TRUE), accuracy = 0.001)`, median absolute deviation = `r number(mad(cor_j, na.rm = TRUE), accuracy = 0.001)`) and genes (median = `r number(median(cor_i, na.rm = TRUE), accuracy = 0.001)`, median absolute deviation = `r number(mad(cor_i, na.rm = TRUE), accuracy = 0.001)`).

<aside>
The genes with the lowest correlations are the aforementioned highly-expressed hemoglobin subunits.
</aside>

```{r within-sample-cors, fig.cap = "Association between UMI counts and read counts for each gene within each sample. The first 8 panels are scatter plots of the UMI counts and read counts for each gene for the samples with the 3 lowest correlations, 2 middlemost correlations, and 3 highest correlations. The correlation in the scatterplot is reported below each panel. The final panel is the distribution of these correlations across all samples.", fig.asp = 1}
par(mfrow = c(3, 3), cex = 0.5)
jj <- names(sort(cor_j)[c(1:3, 195:196, 390:392)])
for (j in jj) {
  g <- rownames(sce)
  plot(
    x = x[, j],
    y = y[, j],
    pch = ".",
    cex = ifelse(g %in% hemo_set, 5, 1),
    col = ifelse(g %in% hemo_set, "red", "black"),
    sub = paste0("r = ", number(cor_j[j], accuracy = 0.001)),
    xlab = expression(log[2](UMIs + 1)),
    ylab = expression(log[2](reads + 1)),
    main = j,
    xlim = c(0, max(x)),
    ylim = c(0, max(y)))
  abline(a = 0, b = 1, col = "grey", lty = 2)
}
plot(
  density(cor_j, na.rm = TRUE, from = -1, to = 1),
  main = "All samples", 
  xlab = expression(r[p]))
```

```{r within-gene-cors, fig.cap = "Association between UMI counts and read counts for each sample within each gene. The first 8 panels are scatter plots of the UMI counts and read counts for each sample for the genes with the 3 lowest correlations, 2 middlemost correlations, and 3 highest correlations. The correlation in the scatterplot is reported below each panel. The final panel is the distribution of these correlations across all genes.", fig.asp = 1}
par(mfrow = c(3, 3), cex = 0.5)
# NOTE: There are some NA correlations, so this changes ii.
ii <- names(sort(cor_i)[c(1:3, 16421:16422, 32849:32851)])
for (i in ii) {
  g <- i
  plot(
    x = x[i, ],
    y = y[i, ],
    pch = 16,
    col = ifelse(g %in% hemo_set, "red", "black"),
    sub = paste0("r = ", number(cor_i[i], accuracy = 0.001)),
    xlab = expression(log[2](UMIs + 1)),
    ylab = expression(log[2](reads + 1)),
    main = i,
    xlim = c(0, max(x)),
    ylim = c(0, max(y)))
  abline(a = 0, b = 1, col = "grey", lty = 2)
}
plot(
  density(cor_i, na.rm = TRUE, from = -1, to = 1),
  main = "All genes", 
  xlab = expression(r[p]))

# Sanity check
stopifnot(identical(names(sort(cor_i))[1:3], c("HBA1", "HBB", "HBA2")))
```

## Summary

As there are so few genes with read counts that exceed the threshold of $4^6 = 4096$ there is little risk that the expression measurements are artificially truncated by using the UMI counts.
Additionally, compared to the read counts, the UMI counts have the advantage that they mitigate the effects of PCR amplification noise.
We therefore opt to use the UMI counts in all the analysis the follows.

```{r}
assay(sce, "counts") <- assay(sce, "UMI_counts")
```

# Quality control of samples

- Danny and Daniel expect the plate with more PCR will have more genes

## Defining the quality control metrics

Low-quality samples need to be removed to ensure that technical effects do not distort downstream analysis results.
We use several quality control (QC) metrics to measure the quality of the samples:

- `sum`: This measures the library size of the samples, which is the total sum of counts across genes. We want samples to have high library sizes as this means more RNA has been successfully captured during library preparation. 
- `detected`: This is the number of expressed features^[The number of expressed genes refers to the number of genes which have non-zero counts (ie. they have been identified in the sample at least once)] in each sample. Samples with few expressed features are likely to be of poor quality, as the diverse transcript population has not been successful captured. 
- `subsets_Mt_percent`: This measures the proportion of reads which are mapped to mitochondrial RNA. If there is a higher than expected proportion of mitochondrial RNA this is often symptomatic of a sample which is under stress and is therefore of low quality and will not be used for the analysis. 

For mini-bulk data, we typically observe library sizes that are in the hundreds of thousands^[This is consistent with the use of UMI counts rather than read counts, as each transcript molecule can only produce one UMI count but can yield many reads after fragmentation.] and several thousand expressed genes per cell.

```{r, results = "hide"}
is_mito <- rownames(sce) %in% mito_set
summary(is_mito)
sce <- addPerCellQC(sce, subsets = list(Mt = which(is_mito)))
```

The aim is to remove putative low-quality samples that have low library sizes, low numbers of expressed features, and high mitochondrial proportions. 
Such samples can interfere with downstream analyses, e.g., by forming distinct clusters that complicate interpretation of the results.

## Visualizing the QC metrics

The distributions of these metrics are shown in Figure \@ref(fig:qcplot), stratified by plate.

```{r qcplot, fig.cap = "Distributions of various QC metrics for all samples in the data set. This includes the library sizes, number of expressed genes, and proportion of reads mapped to mitochondrial genes.", fig.asp = 2 / 3}
plot_grid(
  ggcells(
    sce,
    exprs_values = "counts",
    aes(
      x = plate_number,
      y = sum,
      colour = plate_number, 
      fill = plate_number)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1) +
    scale_fill_manual(values = plate_number_colours) + 
    scale_colour_manual(values = plate_number_colours) + 
    theme_cowplot(font_size = 8) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")) +
    guides(fill = FALSE, colour = FALSE),
  ggcells(
    sce,
    exprs_values = "counts",
    aes(
      x = plate_number,
      y = detected,
      colour = plate_number, 
      fill = plate_number)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1) +
    scale_fill_manual(values = plate_number_colours) + 
    scale_colour_manual(values = plate_number_colours) + 
    theme_cowplot(font_size = 8) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")) +
    guides(fill = FALSE, colour = FALSE),
  ggcells(
    sce,
    exprs_values = "counts",
    aes(
      x = plate_number,
      y = subsets_Mt_percent,
      colour = plate_number, 
      fill = plate_number)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1) +
    scale_fill_manual(values = plate_number_colours) + 
    scale_colour_manual(values = plate_number_colours) + ylim(0, 100) +
    theme_cowplot(font_size = 8) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    guides(fill = FALSE, colour = FALSE),
  ncol = 2,
  align = "v")
```

It is also valuable to examine how the QC metrics behave with respect to each other (Figure \@ref(fig:qcbiplot)). 
Generally, they will be in rough agreement, i.e., samples with low total counts will also have low numbers of expressed features and high mitochondrial proportions.
Clear discrepancies may correspond to technical differences between batches of samples or genuine biological differences in RNA content.

```{r qcbiplot, fig.cap = "Behaviour of each QC metric compared to the total number of expressed features. Each point represents a sample in the data set.", fig.width = 10, fig.asp = 1 / 2}
par(mfrow = c(1, 2))
plot(
  x = sce$detected, 
  y = sce$sum / 1e3,
  pch = 16,
  xlab = "Number of expressed genes",
  ylab = "Library size (thousands)",
  col = sce$plate_number_colours)
legend(
  x = "topleft",
  legend = levels(sce$plate_number),
  col = sce$plate_number_colours[levels(sce$plate_number)],
  pch = 16)
plot(
  x = sce$detected, 
  y = sce$subsets_Mt_percent,
  pch = 16,
  xlab = "Number of expressed genes",
  ylab = "Mitochondrial proportion (%)",
  ylim = c(0, 100),
  col = sce$plate_number_colours)
legend(
  x = "topleft",
  legend = levels(sce$plate_number),
  col = sce$plate_number_colours[levels(sce$plate_number)],
  pch = 16)
```

The results in Figures \@ref(fig:qcplot) and \@ref(fig:qcbiplot) show that more genes are detected on average for samples on plate `LC476` (median = `r number(median(sce$detected[sce$plate_number == "LC476"]), big.mark = ",")`) compared to plate `LC475` (median = `r number(median(sce$detected[sce$plate_number == "LC475"]), big.mark = ",")`).
Furthermore, this required slightly fewer UMIs/sample on average for samples on plate `LC476` (median = `r number(median(sce$sum[sce$plate_number == "LC476"]), big.mark = ",")`) compared to plate `LC475` (median = `r number(median(sce$sum[sce$plate_number == "LC475"]), big.mark = ",")`).
The samples on plate `LC476` do have on average a slightly higher percentage of counts from mitochondrial transcripts (median = `r percent(median(sce$subsets_Mt_percent[sce$plate_number == "LC476"]), scale = 1, accuracy = 0.01)`) compared to plate `LC475` (median = `r percent(median(sce$subsets_Mt_percent[sce$plate_number == "LC475"]), scale = 1, accuracy = 0.01)`), but both are small in absolute terms.

## Identifying outliers by each metric

Outliers are defined based on the median absolute deviation (MADs) from the median value of each metric across all samples. 
We remove small outliers for the library size and the number of expressed features.
Removal of low-quality samples is then performed by combining the filters for all of the metrics.

Due to the differences in the QC metrics by plate, we will compute our outlier thresholds at the plate-level.

```{r}
sce$batch <- sce$plate_number
libsize_drop <- isOutlier(
  metric = sce$sum, 
  nmads = 3,
  type = "lower", 
  log = TRUE,
  batch = sce$batch)
feature_drop <- isOutlier(
  metric = sce$detected,
  nmads = 3, 
  type = "lower", 
  log = TRUE,
  batch = sce$batch,
  # NOTE:# Require a minimum fold-change of 2 from the median (converted into 
  #       log2) to avoid removing samples with several thousand expressed 
  #       genes.
  min_diff = 1)
```

The following table summarises the QC cutoffs:

```{r}
libsize_drop_df <- data.frame(
  plate_number = colnames(attributes(libsize_drop)$thresholds),
  lower = attributes(libsize_drop)$thresholds["lower", ])
feature_drop_df <- data.frame(
  plate_number = colnames(attributes(feature_drop)$thresholds),
  lower = attributes(feature_drop)$thresholds["lower", ])
qc_cutoffs_df <- Reduce(
  function(x, y) dplyr::inner_join(x, y, by = "plate_number"),
  list(libsize_drop_df, feature_drop_df))
colnames(qc_cutoffs_df) <- c(
  "batch", "total counts", "total features")
qc_cutoffs_df %>%
  knitr::kable(caption = "QC cutoffs", digits = 0)
```

```{r}
sce_pre_QC_outlier_removal <- sce
keep <- !(libsize_drop | feature_drop)
sce_pre_QC_outlier_removal$keep <- keep
sce <- sce[, keep]
```

The table below summarises the number of samples per plate left following removal of outliers based on the QC metrics.
The vast majority of samples are retained across both plates.
In total, we remove `r sum(!keep)` samples based on these QC metrics, and retain `r sum(keep)` samples.

```{r}
data.frame(
  ByLibSize = tapply(
    libsize_drop, 
    sce_pre_QC_outlier_removal$batch, 
    sum,
    na.rm = TRUE),
  ByFeature = tapply(
    feature_drop, 
    sce_pre_QC_outlier_removal$batch, 
    sum,
    na.rm = TRUE),
  Remaining = as.vector(unname(table(sce$batch))),
  PercRemaining = round(
    100 * as.vector(unname(table(sce$batch))) /
      as.vector(
        unname(
          table(sce_pre_QC_outlier_removal$batch))), 1)) %>%
  tibble::rownames_to_column("batch") %>%
  dplyr::arrange(dplyr::desc(PercRemaining)) %>%
  knitr::kable(
    caption = "Number of samples removed by each QC step and the number of samples remaining, ordered by the percentage of samples remaining.")
```

```{r}
lc475_dropped <- sce_pre_QC_outlier_removal$well_position[
  !sce_pre_QC_outlier_removal$keep & 
    sce_pre_QC_outlier_removal$plate_number == "LC475"]
lc476_dropped <- sce_pre_QC_outlier_removal$well_position[
  !sce_pre_QC_outlier_removal$keep & 
    sce_pre_QC_outlier_removal$plate_number == "LC476"]
both_dropped <- intersect(lc475_dropped, lc476_dropped)

# Sanity check
stopifnot(identical(lc475_dropped, lc476_dropped))
```

The same `r length(both_dropped)` samples excluded from both plates (`r glue::glue_collapse(both_dropped, sep = ", ", last = " and ")`), which likely indicates an underlying issue with the quality of these samples.

## Summary

To conclude, Figure \@ref(fig:qcplot-post-outlier-removal) shows that post-QC that most samples have similar QC metrics, as is to be expected, and Figure \@ref(fig: breakdown-by-plate-number-post-qc) summarises the experimental design following QC.

```{r qcplot-post-outlier-removal, fig.cap = "Distributions of various QC metrics for all samples that passed quality control. This includes the library sizes, number of expressed genes, and proportion of reads mapped to mitochondrial genes.", fig.asp = 2 / 3}
plot_grid(
  ggcells(
    sce,
    exprs_values = "counts",
    aes(
      x = plate_number,
      y = sum,
      colour = plate_number, 
      fill = plate_number)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1) +
    scale_fill_manual(values = plate_number_colours) + 
    scale_colour_manual(values = plate_number_colours) + 
    theme_cowplot(font_size = 8) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")) +
    guides(fill = FALSE, colour = FALSE),
  ggcells(
    sce,
    exprs_values = "counts",
    aes(
      x = plate_number,
      y = detected,
      colour = plate_number, 
      fill = plate_number)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1) +
    scale_fill_manual(values = plate_number_colours) + 
    scale_colour_manual(values = plate_number_colours) + 
    theme_cowplot(font_size = 8) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")) +
    guides(fill = FALSE, colour = FALSE),
  ggcells(
    sce,
    exprs_values = "counts",
    aes(
      x = plate_number,
      y = subsets_Mt_percent,
      colour = plate_number, 
      fill = plate_number)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1) +
    scale_fill_manual(values = plate_number_colours) + 
    scale_colour_manual(values = plate_number_colours) + ylim(0, 100) +
    theme_cowplot(font_size = 8) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    guides(fill = FALSE, colour = FALSE),
  ncol = 2,
  align = "v")
```

# Examining gene-level metrics

## Inspecting the most highly expressed genes

Figure \@ref(fig:topgenes) shows the most highly expressed genes in the dataset.
Many of these genes are hemoglobin subunit genes, mitochondrial genes, and ribosomal protein.

```{r topgenes, fig.asp = 1, fig.cap = "Percentage of total counts assigned to the top 50 most highly-abundant features in the data set. For each feature, each bar represents the percentage assigned to that feature for a single sample, while the circle represents the average across all samples. Bars are coloured by the total number of expressed features in each samples, while circles are coloured according to whether the feature is labelled as a control feature."}
plotHighestExprs(sce, n = 50)
```

Figure \@ref(fig:topgenes-filtered) shows the most highly expressed after excluding the hemoglobin subunit genes, mitochondrial genes, and ribosomal protein.

```{r topgenes-filtered, fig.asp = 1, fig.cap = "Percentage of total counts assigned to the top 50 most highly-abundant features (after excluding hemoglobin subunit genes, mitochondrial genes, and ribosomal protein genes) in the data set. For each feature, each bar represents the percentage assigned to that feature for a single sample, while the circle represents the average across all samples. Bars are coloured by the total number of expressed features in each sample, while circles are coloured according to whether the feature is labelled as a control feature."}
plotHighestExprs(
  sce, 
  drop_features = c(mito_set, ribo_set, hemo_set),
  n = 50)
```

## Filtering out low-abundance genes

Low-abundance genes are problematic as zero or near-zero counts do not contain much information for reliable statistical inference [@bourgon2010independent].
These genes typically do not provide enough evidence to reject the null hypothesis during testing, yet they still increase the severity of the multiple testing correction.
In addition, the discreteness of the counts may interfere with statistical procedures, e.g., by compromising the accuracy of continuous approximations.
Thus, low-abundance genes are often removed in many RNA-seq analysis pipelines before the application of downstream methods.

The 'optimal' choice of filtering strategy depends on the downstream application.
A more aggressive filter is usually required to remove discreteness (e.g., for normalization) compared to that required for removing underpowered tests.
For hypothesis testing, the filter statistic should also be independent of the test statistic under the null hypothesis.
Thus, we (or the relevant function) will filter at each step as needed, rather than applying a single filter for the entire analysis.

Several metrics can be used to define low-abundance genes.
The most obvious is the average count for each gene, computed across all cells in the data set.
We typically observe a peak of moderately expressed genes following a plateau of lowly expressed genes (Figure \@ref(fig:abhist)).

```{r abhist, fig.cap = "Histogram of log-average counts for all genes in the combined data set.", results = "hide"}
ave_counts <- calculateAverage(sce)
par(mfrow = c(1, 1))
hist(
  x = log10(ave_counts), 
  breaks = 100, 
  main = "", 
  col = "grey",
  xlab = expression(Log[10] ~ "average count"))
to_keep <- ave_counts > 0
sce <- sce[to_keep, ]
```

We remove `r sum(!to_keep)` genes that are not expressed in any sample.
Such genes provide no information and would be removed by any filtering strategy.
We retain `r sum(to_keep)` genes for downstream analysis.

# Concluding remarks

```{r}
saveRDS(
  sce,
  here("data", "SCEs", "C084_Hayman_Pasricha.preprocessed.SCE.rds"),
  compress = "xz")
```

The processed *SingleCellExperiment* object is available (see [`data/SCEs/C084_Hayman_Pasricha.preprocessed.SCE.rds`](../data/SCEs/C084_Hayman_Pasricha.preprocessed.SCE.rds)).
This will be used in downstream analyses, i.e. differential expression analysis.

# Additional information {.appendix}

The following are available on request:

- Full CSV tables of any data presented.
- PDF/PNG files of any static plots.

# Session info {.appendix}

<summary>The analysis and this document were prepared using the following software (click triangle to expand)</summary>
<details>

```{r}
sessioninfo::session_info()
```

</details>
